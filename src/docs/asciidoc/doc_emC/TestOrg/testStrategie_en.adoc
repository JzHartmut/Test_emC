= Test strategies for emC sources (C/C++-Test)
:toc:
:sectnums:
:sectlinks:
:cpp: C++

== Directory-tree gradle-conform


Adequate to the guidelines for arrangement of files in gradle, a directory tree has the following structure:

 +-gradle.build   ... build rules
 +-.gitRepository ... contains path to the .git directory
 +-src
   +-main      ... the sources of the module, without test
   |  +-cpp    ... they are C++ and C sources
   |     +-src_emC
   |        +-.git
   |        +-.gitRepository
   |
   +-test    ... all for test
   |  +-cpp    ... they are C++ and C sources
   |  |  +-emC_TestXYZ ... sources for test of special topics
   |  |  +-emC_TestAll
   |  |     +-testmain.cpp  ... test organisation for test of all
   |  |
   |  +-testScripts  ... Some scripts for special tests to start
   |  +-ZmakeGcc ... Test scripts in jzTxtCmd for whole test with gcc
   |  |  +-ZmakeGcc.jztsh
   |  |
   |  +-VS15  ... Some test projects in Microsoft visual studio 15
   |  +-EclCDT .. some Test projects in Eclipse
   |  +-TI    ... Test on embedded platform (Texas Instruments CCS)
   |  +-QT    ... maybe Test projects in QT developer ...or other tools
   |
   +-docs       ... place for documentation
     +-asciidoc    ... in Asciidoc


That are all sources, able to commit and compare with git. They are two git repositories present:

* One for this whole tree, including all test things, but not the sources.

* A second located in Test_emC/src/main/cpp/src_emC: This is the source repository for the emC, able to include in user applications.

To get this repositories from git hub, use

 git clone https://github.com/JzHartmut/Test_emC.git

This gets the Test sources only. But you can start on windows:

 build.bat

or on Linux set executable rights and then start:

 build.sh

to clone the source tree src_emC, load some more tools, compile and test.


== Infrastructure on the PC for Test_emC

See also link:GitTestEnv_en.html[]

The Test can be run under Windows or Linux.

=== Windows arrangements

On Windows MinGW or adequate should be installed to support sh.exe for unix shell scripts and to offer the Gnu Compiler suite (gcc).

Java as version JRE8 should be available. java as command line should be invoke JRE8. If another version of java is installed as standard, the PATH of the system can be changed temporary or all scripts should be invoked with a locally changed PATH environment setting.

On a Windows PC I have installed an ordinary git:

 c:\Program Files\git
   <DIR>          bin
   <DIR>          cmd
   <DIR>          dev
   <DIR>          etc
   <DIR>          mingw64
   <DIR>          usr
          152.112 git-bash.exe
          151.600 git-cmd.exe
           18.765 LICENSE.txt
          160.771 ReleaseNotes.html


And MinGW for compilation:


 c:\Programs\MinGW
 <DIR>          bin
 <DIR>          include
 <DIR>          lib
 <DIR>          libexec
 <DIR>          mingw32
 <DIR>          msys
 <DIR>          share
 <DIR>          var
 <DIR>          _dll
 <DIR>          _docu


The folder `_dll`  contains


 2016-12-11  23:44           115.214 libgcc_s_dw2-1.dll
 2016-12-11  23:44         1.483.790 libstdc++-6.dll


which are copied from the `c:\Programs\MinGW\bin\` directory. This path `c:\Programs\MinGW\_dll` is in included in the systems `PATH` variable. It is necessary to immediately execute `*.exe`-files which are compiled with MinGW. This both dll are required to execute. The other possibility may be, include `c:\Programs\MinGW\bin\` instead in the `PATH`.

I have written a batch file which is associated to the extension .sh named unix_script.bat :


 @echo off
 set PATH=c:\Programs\MinGW\bin;c:\Programs\MinGW\msys\1.0\bin\; ...
    ... C:\Program Files\git\bin;%PATH%
 set HOMEPATH=\vishia\HOME
 set HOMEDRIVE=D:
 REM -x to output the command as they are executed.
 set SCRIPTPATHB=%1
 set "SCRIPTPATH=%SCRIPTPATHB:\=/%"
 echo %SCRIPTPATH%
 echo on
 sh.exe -c %SCRIPTPATH%

Note that `…​ …`​ is one line. With them a shell script can be executed immediately with double-click, inclusively git commands and mingw execution. The local systems PATH extension includes the git and MinGW executables. The line


 set "SCRIPTPATH=%SCRIPTPATHB:\=/%"


converts the backslash (given on double click in calling argument) to the necessary slash. The `HOMEPATH` and `HOMEDRIVE` variables sets the home directory which is known in Unix/Linux. So you can execute Unix/linux shell scripts nearly usual as in the originals.
aption of the operation system access to Windows). Instead copying the dll you can also include the `c:\Programs\MinGW\bin` in the systems `PATH`, but in my mind it is better to exactly know which dlls are required.


=== Sense or nonsense of local PATH enhancements

You can enhance the `PATH` locally, that is the strategy using `-setEnv.bat` inside the generation scripts for Windows. Note: The enhancement of a script variable in a called script does not work for Unix/linux, but it does work for Windows. That approach is known by all experts.

The other possibility is: On installation process on a special tool the installer enhances the systems settings. Then the tool runs without any scripting. This is the common way for ordinary installations. 

Setting a special path into the `PATH` on script has the advantage for more experience. You will see what is really necessary. You can choose between different toos and versions which uses the same command names (`sh.exe`, `gcc.exe` etc.)
  
  
  
  
== Test strategies: individual and complete tests, documentation

The test of modules (units) has three aspects:

* a) The nightly build test to assure, all is correct. Avoid bugs while improvement.
* b) The manual step by step test to see what is done in detail, the typical developer test. 
* c) Tests document the usage. 

The point a) is the primary for continuous integration. 
The point b) is the most self-evident for the developer, 
one should use firstly this test aspect by himself.
The point c) is the most important for a user of the sources. One can see
how does it works by means of the test (-examples).
  

=== Individual Tests


There are some IDE project files:


* src/test/VS15/All_Test/AllTest_emC_Base.sln: Visual studio


* src/test/EclCDT/emC_Test/.cproject: Eclipse CDT


* TODO maybe QT



Offering special test projects for various topics has not proven successful, because the maintenance of some more projects is a too high effort. Instead, there is exactly one project for any platform (it means at least two, one for Visual Studio and one for Eclipse CDT). To test a special topic there is a main routine which’s calling statements are commented, only the interesting call is used, for single step in debug. This is simple to make.


 #ifdef DEF_MAIN_emC_TestAll_testSpecialMain
 int main(int nArgs, char const*const* cmdArgs )
 {
   STACKTRC_ROOT_ENTRY("main");
   test_Exception();
   test_stdArray();
   //test_Alloc_ObjectJc();
   test_ObjectJc();
   //testString_emC();


This is a snapshot of the current situation. This main routine is used for both IDE.


The include path is IDE- and configuration-specific in the IDE. For both IDEs different path are used for the


 #include <applstdef_emC.h>


This file(s) should be changed for several Variants for emC compilation. Of course any commit contains the last used situation, not a developer progress in any case.



The applstdef are located in image:../../img/Test_emC/applstdef_Location_VStudio.png[applstdef_Location_VStudio, float="right", align="top"]


 D:\vishia\emc\Test_emC\src\test\VS15\All_Test
          1.651 AllTest_emC_Base.sln
 <DIR>          applstdef_C1
 <DIR>          applstdef_CppObj


It is for Visual Studio. The same set of files, but other files are existing for Eclipse-CDT, see project.


=== What is tested? C-sources, compiler optimization effects and in target hardware

Firstly the algorithm of the C-sources should be tested. 
It should be independent of the used compiler and there options. Hence 
any compiler can be used for test of the sources, 
for example a Visual Studio compiler, gcc or other. 

Secondly, it is possible that an algorithm works proper with the selected compiler,
but fails in practice on an embedded hardware. What is faulty? It is possible 
that the target compiler has better optimization, and a property keyword such as 
`volatile` is missing in the source. It is a real failure in the source,
but it was not detected by the test run with lower optimization.

In conclusion of that, the compiler and its optimization level 
should be carefully set. The test should be done with more as one compiler
and with different optimization levels. For nightly tests the night may be long enough. 

The next question is: "Test in the real target hardware". 
An important answer is: 
"The test should not only be done in the special hardware environment,
the sources should be tested in different environment situations". 
For example, an algorithm works properly in the special hardware environment 
because some data are shortened, but the algorithm is really faulty. 
Ergo, test it in different situations. 

But the test in the real target environment, with the target compiler,
running inside the real hardware platform may be the last of all tests. 
It can be done as *integration test* of course, but the modules can be tested
in this manner too. 
 
It means, the test should compile for the target platform, 
load the result into the target hardware, run there, get error messages for example
via a serial output, but run it as module test. 
Because not all modules may be able to load in one binary (it would be too large),
the build and test process should divide the all modules in proper portions 
and test  one after another, or test parallel in more as one hardware board.
  
== Test of all for algorithm test with gcc with some variants

Because the test should run on PC the gcc compiler is favored for the common test_all. This common test is described in link:GitTestEnv_en.html[Test environment for Test_emC from git archive] as how-to-documentation.


=== Generate a script with compile and commands 

The compiler is invoked as command in a script. The script contains the immediately real compiler invocation. It is not a make script which builds the compiler invocation internally using some dependencies, settings etc. The advantage of immediately real compiler invocation is: **It is immediately documented what is happen**.

To generate this compiler invocation script a  link:https://vishia.org/JZtxtcmd/html/JZtxtcmd.html[] script is used:

 D:\vishia\emc\Test_emC\src\test\ZmakeGcc
           17.656 ZmakeGcc.jztsh  <<===

This script is a make script, it contains the information how to make. The script defines a text translation, not a standard gcc make. The output of the translation are some shell scripts which invokes compiling, linking and executing for different test conditions. This output files are written to 

 D:\vishia\emc\Test_emC\build
   <DIR>          result
   <DIR>          dbgBhClassJcFull
   <DIR>          dbgBheap
   <DIR>          dbgBhSimple
           52.640 make_dbgBhClassJcFull.sh <<===
           50.299 make_dbgBheap.sh         <<===
           53.040 make_dbgBhSimple.sh      <<===

It is a snapshot with three test files. To produce it, the `ZmakeGcc.jztsh` is included in some simple user script, which defines what to make. This scripts are contained in:

  D:\vishia\emc\Test_emC\src\test\testScripts
            35 stimuliGUI.sh
         1.470 testBasics_All.jzTc.sh
           991 testBasics_Simple.jzTc.sh
         1.493 testEvMsgCtrl_All.jztsh

`testBasics_Simple.jzTc.sh` invokes only two compilations, two test.exe, to check whether the test system runs proper. This script should be start as a unix-shell script as explained in link:GitTestEnv_en.html[]. It contains:

 if test -f testBasics_Simple.jzTc.sh; then cd ../../..; fi
 pwd
 java -jar libs/vishiaBase.jar src/test/testScripts/testBasics_Simple.jzTc.sh                      
 ##Execute the even yet generated sh scripts, compile and execute: 
 build/testBasics_Simple.sh
 read -n1 -r -p "Press any key to continue..."
 exit 0  ##the rest of the file is the JZtxtcmd script                                      
                                                                   
 ==JZtxtcmd==
 include ../ZmakeGcc/test_Selection.jztsh;
 currdir=<:><&scriptdir>/../../..<.>;                             

 main() {
  call genTestcases(select="iqnsB:IJrSB", name = "testBasics_Simple");
 }

The magic characters defines what to test. `testBasics_Simple` is the name of the start shell script for the test. See next chapter.



=== Test Selection - arrange test cases

The problem on testing the core emC sources is the variety of variants (yet 124 combinations) for `ObjectJc`, `Exceptionhandling` etc. Writing a lot of scripts, and adjusting the compile switches in `applstdef_emC.h` was a too high effort. Hence a '__Select Simulation__' tool is used, which cames originally from Simulink stimuli selections written by me in the past. It is written in Java and contained in `libs/vishiaGui.jar`. This tool works with tables. 

image:../../img/Test_emC/SimSelector.png[Select Simulation, float="left", align="top"]

The same tables as for the manual operating graphic tool are used to arrange the conditions for the test cases. The `src/test/ZmakeGcc/testObjSiReflNo_AllExc.jzTc.sh` controls the '__SimSelector__' too. For example the table for Selecting the kind of reflection generation looks like:

 List tabRefl = 
 [ { name="ReflNo",   descr="..ReflNo",       select="q", def1="DEF_REFLECTION_NO"      }
 , { name="ReflSi",   descr="..ReflSi",       select="r", def1="DEF_REFLECTION_SIMPLE"  }
 , { name="ReflOffs", descr="..ReflOffs",     select="Q", def1="DEF_REFLECTION_OFFS"    }
 , { name="ReflFull", descr="..ReflFull",     select="R", def1="DEF_REFLECTION_FULL"    }
 ];

It is a data list in link:../../../JZtxtcmd/html/JZtxtcmd.html[]. You see the magic character in the list and in the '__Select Simulation__'. The table contains immediately the necessary compiler switches for each of the four test variants.

Either a line is selected in the '__Select Simulation__', or a character is given. With the adequate information the sub routine

 sub genSelection(Map line1, Map line2, ..., Obj fAllsh) { ...
 
is invoked. It gets the selected line in each table. `line2` is from the table above. With the information in the line the compiler switches in the test script can be arragenged in a simple way. The texts are contained in the line. 

The 

 sub genTestcases(String select, String name) { ...

which is called from the test start script searches the correct lines with the given magic chararcter, which are found in the line. A nice helper is a Java class: 

link:../../../Java/docuSrcJava_vishiaBase/org/vishia/util/StringFunctions_B.html#checkSameChars-java.lang.CharSequence...[class org.vishia.util.StringFunctions_B.checkSameChars] 

which compares the given selection character with the content if line.select. So the information in the tables and the magic character come together. 


=== Arranging the necessary compile units

The 3. table in the '__Select Simulation__' contains, which is to test, yet only two variants. (The other tables contains, 'under which condition is to test'). It looks like (shortend):

 List tabTestSrc =                               
 [ { name="TestBase", select="B", srcSet="srcTestBasics", def1="DEF_TESTBasics_emC"}
 , { name="TestEvMsg",select="M", srcSet="srcTestEvMsg",  def1="DEF_TESTALL_emC" }
 ];

The `srcSet` is the name of a file set, defined in this script too:

 ##
 ## main file for Basic tests.
 ##
 Fileset srcTestBasics =
 ( src/test/cpp:emC_TestAll\testBasics.cpp
 , src/test/cpp:emC_TestAll\test_exitError.c
 , &srcTest_ObjectJc
 , &srcTest_Exception
 , &src_Base_emC_NumericSimple
 );

A `Fileset` is a core capability from link:../../../JZtxtcmd/html/JZtxtcmd.html[]. It names some files and sub Filesets. 

The `Fileset`s are cut so that defined files are named for some application goals. This information can be used to select which emC files are need as part of a maybe simple application:

 Fileset src_Base_emC_NumericSimple = 
 ( src/main/cpp/src_emC:emC_srcApplSpec/SimpleNumCNoExc/fw_ThreadContextSimpleIntr.c
 , src/main/cpp/src_emC:emC_srcApplSpec/SimpleNumCNoExc/ThreadContextSingle_emC.c
 , src/main/cpp/src_emC:emC_srcApplSpec/applConv/LogException_emC.c
 );

The fileset 

 ##                                                                          
 ##The real core sources for simple applications only used ObjectJc.
 ##See sub build_dbgC1(), only the OSAL should be still added.  
 ##
 Fileset c_src_emC_core =                                        
 ( src/main/cpp/src_emC:emC/Base/Assert_emC.c
 , src/main/cpp/src_emC:emC/Base/MemC_emC.c
 , src/main/cpp/src_emC:emC/Base/StringBase_emC.c
 , src/main/cpp/src_emC:emC/Base/ObjectSimple_emC.c 
 , src/main/cpp/src_emC:emC/Base/ObjectRefl_emC.c
 , src/main/cpp/src_emC:emC/Base/ObjectJcpp_emC.cpp 
 , src/main/cpp/src_emC:emC/Base/Exception_emC.c     
 , src/main/cpp/src_emC:emC/Base/ExceptionCpp_emC.cpp
 , src/main/cpp/src_emC:emC/Base/ExcThreadCxt_emC.c
 , src/main/cpp/src_emC:emC/Base/ReflectionBaseTypes_emC.c
 , src/main/cpp/src_emC:emC_srcApplSpec/applConv/ExceptionPrintStacktrace_emC.c
 ##Note: Only for test evaluation
 , src/main/cpp/src_emC:emC/Test/testAssert_C.c
 , src/main/cpp/src_emC:emC/Test/testAssert.cpp
 , src/test/cpp:emC_TestAll/outTestConditions.c
 , &src_OSALgcc
 , src/main/cpp/src_emC:emC_srcApplSpec/applConv/ObjectJc_allocStartup_emC.c
 );

are the core sources for test. Maybe not all, but from this selection may be necessary to use as core sources for an application, which uses emC. It documents the necessities and indirectly also the dependencies.




=== Distinction of several variants of compilation

The distinction between C and {cpp} compilation can be done using either `gcc` for `*.c`-Files or `g++` which always compiles as {cpp}. This is the content of the special `build_...` routine. Some more `build_...` routines are existing for different used files and for decision between C and {cpp} compilation. 


The distinction between conditional compilation (variants, see link:../Base/Variants_emC.html[] are done with the different content of the `cc_def` variable. It contains '-D ...' arguments for the compilation. The other variant may be selecting different `<applstdef_emC.h>` files which is recommended for user applications. Then the include path should be varied. It needs some `applstdef_emC.h` files. This can be done too, the part of the include path to `<applstdef_emC.h>` is contained in the `cc_def` variable.




[#checkDeps]
=== Check dependency and rebuild capability

A file should be compiled:

* If the object file does not exist
* If the source file is newer than the object file (or more exactly: The content of the source file was changed in comparison to the content of the last compilation).
* If any of the included source files (e.g. header) is newer than  the object file (respectively changed after last using).

The first two conditions are checked only with the 'is newer' aspect from a ordinary make file. For the third condition (indirect newly) the dependencies between the files should be known.
For a classic make files this dependencies can be given - if they are known.
In practice the dependencies depends on the include situation, it is not simple.
Hence the real dependencies can only detect for a concretely version of the file, and the make script should correct any time. IDEs use their native dependency check. 

Because this cannot be done easily, often there is a '__build all__' mentality.

For repeated compilation the '__build all__' mentality needs to much time. 

For this approach a Java package `org.vishia.checkDeps_C` is used. See 

link:../../../JZtxtcmd/html/CheckDeps_C.html[].

This tool uses a comprehensive file `deps.txt` which contains the dependency situation of each file and the timestamp and content situation (via CRC checksum). The tool checks the time stamp and the content of all depending files from the list. If one file is changed, it is parsed by content, find out include statements and build newly the dependencies from this level. Ones of course the object should be recompiled, because another content may be changed. Secondly the dependencies for the test later are corrected.. 

Because the dependency file contains the time stamp of any source file, it is detected whether an older file is given. The comparison of time stamps is not the comparison between source and object, it is the comparison between the last used source and the current source time stamp. The newly compilation is done also if the file is older, not only newer than the object file. This is an expectable situation, if a file is changed by checkout from a file repositiory with its originally time stamp (the older one). Because git and some other Unix/linux tools stores an older file with the current timestamp this problem is not present on linux, but Windows restores or preserves the time stamp of a copied file, which may be the better and here supported approach.   

If the dependency file is not existing, it means, the dependencies should be detected, build all is necessary and the dependency file is built. This is the situation on first invocation after clean.

The dependency file is stored inside the object directory:

 ...\build\objZmake\test_ObjRefl_ReflFull_ThSi_ExcNo_StrNo_TestEvMsg
 <DIR>          emC
 <DIR>          emC_Exmpl_Ctrl
 <DIR>          emC_srcApplSpec
 <DIR>          emC_srcOSALspec
 <DIR>          emC_TestAll
 <DIR>          emC_Test_Container
 <DIR>          emC_Test_Ctrl
 <DIR>          emC_Test_C_Cpp
 <DIR>          emC_Test_ObjectJc
 <DIR>          emC_Test_Stacktrc_Exc
        362.272 deps.txt                 <<=======
          8.330 checkDeps.out
        295.817 emCBase_.test.exe
            296 fDefSelection.h
              0 ld_out.txt

It is a snapshot from the root of the object dir tree. The `deps.txt` has about 260 kByte, it is not too long. The Java algorithm to check the dependencies of all files reading this file needs only milliseconds, because like known, Java is very fast.  

You can view this file to explore the individual dependencies of each file, which may be informative.

The dependency check is part of each `make..sh` shell script (generated):

 ...\build\objZmake
          2.965 deps_test_ObjRefl_ReflFull_ThSi_ExcNo_StrNo_TestEvMsg.args
         72.677 make_test_ObjRefl_ReflFull_ThSi_ExcNo_StrNo_TestEvMsg.sh
 <DIR>          test_ObjRefl_ReflFull_ThSi_ExcNo_StrNo_TestEvMsg


 ....
 echo run checkDeps, see output in build/...testCase/checkDeps.out
 java -cp libs/vishiaBase.jar org.vishia.checkDeps_C.CheckDeps ...  
   ... --@build/objZmake/deps_test_ObjRefl_ReflFull_ThSi_ExcNo_StrNo_TestEvMsg.args ...
   ... > build/objZmake/test_ObjRefl_ReflFull_ThSi_ExcNo_StrNo_TestEvMsg/checkDeps.out 

( The `java` invocation is a long line). 

The check of the unchanged situation does only need reading the time stamps of all depending files, it is very fast because the file system is usual cached. 
If dependencies should be evaluate newly all source files are parsed. Of course already parsed included files are not proceed twice. The parsing, and checking for `# include` statement, does only need a short time because Java is fast. The gcc compiler itself supports a dependency check too, but that is very slower (not because {cpp} is slow, but because it may be more complex. The `checkDeps` dependency check is more simple, for example it does not regard conditional compilation (a conditional include). It means, it detects a dependency to a included file which is not active in the compiling situation. But that is not a disadvantage, because the dependency can be exist, and the unnecessary compilation because of one conditional include does not need more time than the elaborately dependency check. 

If the object file should be recompiled, the `checkDeps` algorithm deletes it and forces a recompilation because existency check of the object file before compilation. It is a simple liaison between this independent tools. 





=== View of test results

TODO

All is written in result with proper names. Compare basing on text file comparison.
If all files are equal, the test delivers the same result. If a file is slightly different, it can be occure because output of lines which may be changed in the source, but the result is ok.
A red-yellow-green report is not produced yet. TODO for a fast overview. 

OLD content

The execution of the compiled `build/test_case/*.exe` writes its result to a file in `build/result/test_case.out`. Check its timestamp and compare it with the stored reference results in `ref/test_case.out`. 

The sources uses the link:#testCheck[chapter: Test check and results] approach. Hence it writes:

 Test: Name of the test (testfile @line)
   ok: Description of detail test
   ERROR: Description of detail test (testfile @line)
 ok
 
for each test routine. If an `ERROR:` was written, then refer the line and repeat the test using single step debugging on the IDE with the given variant settings (adjust `<applstdef_emC.h>`

Addtional an output text can be written, for example testing the exception handling:

 Test: test_Exception: (emC_Test_Stacktrc_Exc/TestException.cpp @ 95) ...
  ok: TRY without THROW with FINALLY is ok 
  ok: File hint found in Exception
  ok: Exceptiontext: faulty index:10 for value 2.000000(10, 0) in: src/test/cpp/emC_Test_Stacktrc_Exc/TestException.cp4
 Exceptiontext: faulty index:10 for value 2.000000(10, 0) in: src/te....
 IndexOutOfBoundsException: faulty index:10 for value 2.000000: 10=0x0000000A 
  at THROW (src/test/cpp/emC_Test_Stacktrc_Exc/TestException.cpp:41)
  at testThrow (src/test/cpp/emC_Test_Stacktrc_Exc/TestException.cpp:34)
  at test_Exception (src/test/cpp/emC_Test_Stacktrc_Exc/TestException.cpp:118)
  at main (src/test/cpp/emC_TestAll/testmain.cpp:75)
  ok: simple THROW is catched. 
  ok: TRY without THROW after an Exception before has not entered CATCH BLOCK 

In this case the programmed console output of the exception message and stack trace is shown. The distinction between Test outputs and programmed outputs is `Test:`, ` ok:`  and ` ERROR:` on start of line, see examples above.  





[#testCheck]
== Test check and output in the test files

TODO it's an older content.

The tests should work silent for nightly tests if they don't fail. It should be possible
to output some information, one line per test, what is tested. 

Test results are checked with macros

 EXPECT_TRUE(condition) << "additional test information";
 
etc., the same macros as used for Google-Tests are used, 
but the whole google test framework itself is not used here. The `EXPECT...`-Macros
are defined in the following kind: 

 #define EXPECT_TRUE(VAL) \
 if(EXPECT_TRUEmsg1(VAL, __FILE__, __LINE__)) std::cerr
 
The routine `EXPECT_TRUEmsg1(...)` returns false if the condition is true, 
if no message should be output.
Hence the `if(...)` construct with the following statement starting with `std:cerr` 
completed with `<< "additional text` in the users code forces the output only on error. 

Only if the test fails, the file and line is reported, after them the user message.
With this information the test can be found out simple by the developer.  

It is a simple writing style for application of this macro. 

The test macros and operations are defined in `org/vishia/emC/Test/testAssert.h` and `~.c` 
in the emC_Base component, able to use in al emC sources out of test too.



== Test environment, mock, dependency injection

(additonal content with common meaning, TODO)

The test routines itself calls one or some routines from the module sources 
in an environment arranged in the respective test routine. If instances are necessary,
they are created and removed after test in the test routine. If additional depending
complex modules are necessary, they should be replaces by mock objects because elsewhere
the other module is tested too in a complex non-independent kind. The mock object
should be simple and can contain some helper for checking the test behavior. 
The possible usage of dependency injection instead instantiating of composite objects
inside the test object is a problem of the module source, not a problem of the test itself.

 
